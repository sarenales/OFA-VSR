{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarenales/VSR-Retrival/blob/main/ejemplo_infer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KjGJpIoA3pWo",
        "outputId": "04040e8d-857f-44fa-da10-a0c565892555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OFA'...\n",
            "remote: Enumerating objects: 5745, done.\u001b[K\n",
            "remote: Counting objects: 100% (932/932), done.\u001b[K\n",
            "remote: Compressing objects: 100% (256/256), done.\u001b[K\n",
            "remote: Total 5745 (delta 710), reused 676 (delta 676), pack-reused 4813\u001b[K\n",
            "Receiving objects: 100% (5745/5745), 97.78 MiB | 12.93 MiB/s, done.\n",
            "Resolving deltas: 100% (2243/2243), done.\n",
            "Updating files: 100% (3223/3223), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --single-branch --branch feature/add_transformers https://github.com/OFA-Sys/OFA\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OFA/transformers/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "U3NN7JVBp-BB",
        "outputId": "94932aa8-7ef5-4835-e488-d826ec4e4ae2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./OFA/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0.dev0) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0.dev0) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0.dev0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0.dev0) (2.31.0)\n",
            "Collecting sacremoses (from transformers==4.18.0.dev0)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0.dev0) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0.dev0) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0.dev0) (2024.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0.dev0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0.dev0) (1.4.2)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.18.0.dev0-py3-none-any.whl size=3916748 sha256=cc03eb33a555ebb751a8bd287016edf41ca0833b3433525c5adde924313a918a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9sni222z/wheels/0b/bc/ea/00b6b8998c20c4fe55affe6062a2cddda80308ef9bd5d5877c\n",
            "Successfully built transformers\n",
            "Installing collected packages: sacremoses, transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "Successfully installed sacremoses-0.1.1 transformers-4.18.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gcsY6reiX07"
      },
      "source": [
        "# OFA infering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qQ2biwWx6ECo",
        "outputId": "9f49bb47-08a4-439f-8d88-e99a05828725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'OFA-huge'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Total 40 (delta 0), reused 0 (delta 0), pack-reused 40 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (40/40), 539.60 KiB | 4.25 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/OFA-Sys/OFA-huge"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.ofa.generate import sequence_generator"
      ],
      "metadata": {
        "id": "JkaeLt1CqJwY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yvZH2TWB6bDi",
        "outputId": "994a0656-06a9-43e1-a4f1-0fd401c8e679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./OFA-huge\n",
            "<super: <class 'OFATokenizer'>, <OFATokenizer object>>\n"
          ]
        }
      ],
      "source": [
        "from transformers import OFATokenizer, OFAModel\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ofa_model = OFAModel.from_pretrained(\"./OFA-huge\", use_cache=False).to(device)\n",
        "ofa_tokenizer = OFATokenizer.from_pretrained(\"./OFA-huge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ekt8RjBt6mAE"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "mean, std = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
        "resolution = 480\n",
        "\n",
        "def load_image(image):\n",
        "    patch_resize_transform = transforms.Compose([\n",
        "            transforms.Resize((resolution, resolution), interpolation=Image.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean, std=std)\n",
        "        ])\n",
        "    patch_img = patch_resize_transform(image).unsqueeze(0).to(device)\n",
        "    return patch_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ejemplo = {'image': '000000574696.jpg',\n",
        "  'image_link': 'http://images.cocodataset.org/train2017/000000574696.jpg',\n",
        "  'caption+': 'The zebra is far away from the car.',\n",
        "  'caption-': 'The zebra is close to the car.',\n",
        "  'annotator_id': '2',\n",
        "  'relation+': 'far away from',\n",
        "  'relation-': 'close to',\n",
        "  'split': 'train'}"
      ],
      "metadata": {
        "id": "biIsw6X_FYG8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ejemplo_nina = {'image': '000000293372.jpg',\n",
        "  'image_link': 'http://images.cocodataset.org/train2017/000000293372.jpg',\n",
        "  'caption+': 'The person is on top of the bed.',\n",
        "  'caption-': 'The person is beneath the bed.',\n",
        "  'annotator_id': '35',\n",
        "  'relation+': 'on top of',\n",
        "  'relation-': 'beneath',\n",
        "  'split': 'train'}"
      ],
      "metadata": {
        "id": "45MkPmVnBRaD"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ejemplo_gato = {'image': '000000209558.jpg',\n",
        "  'image_link': 'http://images.cocodataset.org/train2017/000000209558.jpg',\n",
        "  'caption+': 'The tv is beside the cat.',\n",
        "  'caption-': 'The tv is far from the cat.',\n",
        "  'annotator_id': '29',\n",
        "  'relation+': 'beside',\n",
        "  'relation-': 'far from',\n",
        "  'split': 'train'}"
      ],
      "metadata": {
        "id": "VNKDlgrD-xlG"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ejemplo_caballo = {'image': '000000424912.jpg',\n",
        "  'image_link': 'http://images.cocodataset.org/train2017/000000424912.jpg',\n",
        "  'caption+': 'The person is on top of the horse.',\n",
        "  'caption-': 'The person is beneath the horse.',\n",
        "  'annotator_id': '27',\n",
        "  'relation+': 'on top of',\n",
        "  'relation-': 'beneath',\n",
        "  'split': 'train'}"
      ],
      "metadata": {
        "id": "-HwWoLOLz9EW"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zoo6zXs5iUKc"
      },
      "outputs": [],
      "source": [
        "ejemplo_zebra2 = { 'image': '000000556341.jpg',\n",
        "  'image_link': 'http://images.cocodataset.org/train2017/000000556341.jpg',\n",
        "  'caption+': 'The zebra is at the right side of the person.',\n",
        "  'caption-': 'The zebra is at the left side of the person.',\n",
        "  'annotator_id': '27',\n",
        "  'relation+': 'at the right side of',\n",
        "  'relation-': 'at the left side of',\n",
        "  'split': 'train'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUB1y9doeKUY"
      },
      "source": [
        "#1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import math\n",
        "from torch import nn\n",
        "from io import BytesIO\n",
        "from tabulate import tabulate\n"
      ],
      "metadata": {
        "id": "iqvJV4mj9HlS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F4ay0LD6e-O2"
      },
      "outputs": [],
      "source": [
        "def token_imag(url):\n",
        "  response = requests.get(url)\n",
        "  image = Image.open(BytesIO(response.content))\n",
        "  patch_img = load_image(image.convert(\"RGB\"))\n",
        "  return patch_img, image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "APsEs2Aze_Pp"
      },
      "outputs": [],
      "source": [
        "def token_cap(caption):\n",
        "  cap = \"Does the image describe the following sentence?  \" + caption\n",
        "  text = ofa_tokenizer([cap], padding=True, truncation=True, return_tensors=\"pt\").to(device).input_ids\n",
        "  return text,cap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IYwNyWhKfAZ9"
      },
      "outputs": [],
      "source": [
        "def input_model(caption, patch_img):\n",
        "  gen_output_0 = ofa_model.generate(caption, patch_images=patch_img,num_beams=1, no_repeat_ngram_size=1,  return_dict_in_generate=True , output_scores=True )\n",
        "  ofa_caption_0 = ofa_tokenizer.batch_decode(gen_output_0[0], skip_special_tokens=True)[0].strip()\n",
        "  return ofa_caption_0, gen_output_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mBEDte2HfEca"
      },
      "outputs": [],
      "source": [
        "def get_probabilidades(gen_output_0):\n",
        "  probabilities = nn.functional.softmax(gen_output_0[1][0], dim=-1)\n",
        "  probYES = probabilities[0][tokens.get(\"yes\")].item()\n",
        "  probNO = probabilities[0][tokens.get(\"no\")].item()\n",
        "  return probYES, probNO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjSP9uWagWnO",
        "outputId": "02f16e2d-87fd-4df9-9e5b-cb84c1942112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ],
      "source": [
        "resultados = {}\n",
        "tokens = ofa_tokenizer.get_vocab()\n",
        "\n",
        "cont = 0\n",
        "\n",
        "probYESP = 0.0\n",
        "probNOP = 0.0\n",
        "probYESN = 0.0\n",
        "probNON = 0.0\n",
        "respP = \"\"\n",
        "respN = \"\"\n",
        "\n",
        "url = ejemplo[\"image_link\"]\n",
        "patch_img,image = token_imag(url)\n",
        "\n",
        "caption = token_cap(ejemplo[\"caption+\"])[0]\n",
        "ofa_caption_0, gen_output_0 = input_model(caption, patch_img)\n",
        "respP = ofa_caption_0\n",
        "probYESP, probNOP = get_probabilidades(gen_output_0)\n",
        "\n",
        "caption = token_cap(ejemplo[\"caption-\"])[0]\n",
        "ofa_caption_1, gen_output_1 = input_model(caption, patch_img)\n",
        "respN = ofa_caption_1\n",
        "probYESN, probNON = get_probabilidades(gen_output_1)\n",
        "\n",
        "ejemplo[\"PY+\"] = probYESP\n",
        "ejemplo[\"PN+\"] = probNOP\n",
        "ejemplo[\"response+\"] = respP\n",
        "ejemplo[\"PY-\"] = probYESN\n",
        "ejemplo[\"PN-\"] = probNON\n",
        "ejemplo[\"response-\"] = respN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-6Omot1g012",
        "outputId": "1a6744e3-a837-4cfa-b8fc-45e198ecdd25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does the image describe the following sentence?  The zebra is far away from the car.\n",
            "OFA caption + : yes\n",
            "OFA caption - : yes\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(token_cap(ejemplo[\"caption+\"])[1])\n",
        "print(\"OFA caption + :\",ofa_caption_0)\n",
        "print(\"OFA caption - :\",ofa_caption_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z20h06xjeJDi"
      },
      "source": [
        "#2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0VeGU0HMi0FV"
      },
      "outputs": [],
      "source": [
        "def acierta_1(PYP,PNP,PYN,PNN):\n",
        "  DP = abs(PYP - PNP)\n",
        "  DN = abs(PYN - PNN)\n",
        "\n",
        "  if DN == 0.0:\n",
        "    return 0\n",
        "  if DP == 0.0:\n",
        "    return 0\n",
        "\n",
        "  if DP > DN :\n",
        "    return 1\n",
        "  return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "34ncyl5Wi8_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cbffbb8-3a15-4acf-e57a-d6b3fd19cc65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FALLA \n"
          ]
        }
      ],
      "source": [
        "datos_filtrados = []\n",
        "\n",
        "\n",
        "rel_esp = ejemplo[\"relation+\"]\n",
        "acierto = acierta_1(ejemplo[\"PY+\"],ejemplo[\"PN+\"],ejemplo[\"PY-\"],ejemplo[\"PN-\"])\n",
        "datos_filtrados.append({\"relacion_espacial\": rel_esp, \"acierto\": acierto})\n",
        "if acierto == 1:\n",
        "  print(\"ACIERTA\")\n",
        "else:\n",
        "  print(\"FALLA \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R76mOaWUjats",
        "outputId": "2fbac8c6-0de8-436f-eb93-e69213bca19d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.817415740239085e-07"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "ejemplo[\"PY+\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ejemplo[\"PN+\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XgQC0vEwaQ1",
        "outputId": "0c563353-2bb3-4d5d-ade8-38fbe7179a72"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.238249987220115e-08"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mFe7PAOjq7s",
        "outputId": "ce33800f-70fb-4567-981d-03d45f9d8f02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.82908876115107e-07"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "ejemplo[\"PY-\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ejemplo[\"PN-\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUMdjzbxw25_",
        "outputId": "b80bf597-8d9a-42bb-9244-72f61fb46a51"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.764033896733963e-07"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LavaoDsNjw5x"
      },
      "outputs": [],
      "source": [
        "def acierta_2(PYP,PNP,PYN,PNN):\n",
        "  if PYP == 0.0:\n",
        "    return 0\n",
        "  if PYN == 0.0:\n",
        "    return 0\n",
        "\n",
        "  total_prob_p = PYP + PNP\n",
        "  normalized_prob_yes_p = PYP / total_prob_p\n",
        "  normalized_prob_no_p = PNP / total_prob_p\n",
        "\n",
        "  total_prob_n = PYN + PNN\n",
        "  normalized_prob_yes_n = PYN / total_prob_n\n",
        "  normalized_prob_no_n = PNN / total_prob_n\n",
        "\n",
        "  if normalized_prob_yes_p > normalized_prob_no_n:\n",
        "    return 1\n",
        "  return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wjgJH5a_j0Fh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "149db1eb-e623-4ed4-875a-d4ff69d6368f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACIERTA\n"
          ]
        }
      ],
      "source": [
        "datos_filtrados = []\n",
        "\n",
        "\n",
        "rel_esp = ejemplo[\"relation+\"]\n",
        "acierto = acierta_2(ejemplo[\"PY+\"],ejemplo[\"PN+\"],ejemplo[\"PY-\"],ejemplo[\"PN-\"])\n",
        "datos_filtrados.append({\"relacion_espacial\": rel_esp, \"acierto\": acierto})\n",
        "if acierto == 1:\n",
        "  print(\"ACIERTA\")\n",
        "else:\n",
        "  print(\"FALLA \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sZ8dhEheHzg"
      },
      "source": [
        "# 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def token_imag(url):\n",
        "  response = requests.get(url)\n",
        "  image = Image.open(BytesIO(response.content))\n",
        "  patch_img = load_image(image.convert(\"RGB\"))\n",
        "  return patch_img, image"
      ],
      "metadata": {
        "id": "kEgIRcMBqqZU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_cap(caption):\n",
        "  text = ofa_tokenizer([caption], padding=True, truncation=True, return_tensors=\"pt\").to(device).input_ids\n",
        "  return text"
      ],
      "metadata": {
        "id": "7Eqr-jCJqrT9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tbVK30za-2on"
      },
      "outputs": [],
      "source": [
        "def probability_to_logit(p):\n",
        "    p = p.item()\n",
        "    if p == 0.0:\n",
        "        return -10000\n",
        "    return np.log(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "txMW1R0cm4rk"
      },
      "outputs": [],
      "source": [
        "def partes(caption):\n",
        "  partes = caption.split()\n",
        "  palabras = []\n",
        "  for parte in partes:\n",
        "    palabras.extend(parte.split(\".\"))\n",
        "  palabras[-1] = \".\"\n",
        "  palabras.append(\"</s>\")\n",
        "  return palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6CJT2GbtnjwX"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def pro_logs(logits_output, caption):\n",
        "  sum_pro = 0\n",
        "  mul_pro = 0\n",
        "  suma_log1 = 0\n",
        "  suma_log2 = 0\n",
        "  datos = []\n",
        "  datos.append((\"Token\", \"Logit 1\",\"Probabilidad de la siguiente\", \"Logit 2\"))\n",
        "  inputs_pal = []\n",
        "  inputs_ids = []\n",
        "  for i in partes(caption):\n",
        "    inputs_pal.append(i)\n",
        "\n",
        "  cont = 0\n",
        "  for i in range(0, len(inputs_pal)-1):\n",
        "    inputs_ids = (ofa_tokenizer(inputs_pal[i]).input_ids)\n",
        "    for j in inputs_ids[1:-1]:\n",
        "      probabilities = nn.functional.softmax(logits_output.logits, dim=-1)\n",
        "      log_1 = logits_output.logits[0][cont][j].item()\n",
        "      prob = probabilities[0][cont][j]\n",
        "      log_2 = probability_to_logit(prob)\n",
        "      datos.append((ofa_tokenizer.decode([j]), log_1, prob.item(), log_2))\n",
        "      cont += 1\n",
        "      suma_log1 += log_1\n",
        "      sum_pro += prob\n",
        "      mul_pro *= prob\n",
        "      suma_log2 += log_2\n",
        "  datos.append((\"</s>\", 0.0, 0.0, 0.0))\n",
        "  print(tabulate(datos, headers=\"firstrow\", tablefmt=\"grid\"))\n",
        "  print(f\"Probabilidad media  : {(sum_pro/len(partes(caption))).item()} \")\n",
        "  print(f\"Mul probabilidades  : {mul_pro} \")\n",
        "  print(f\"Suma logits 1       : {suma_log1} \")\n",
        "  print(f\"Suma logits 2       : {suma_log2} \")\n",
        "  return (sum_pro/len(partes(caption))).item() , mul_pro, suma_log1, suma_log2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import math\n",
        "from torch import nn\n",
        "from io import BytesIO\n",
        "from tabulate import tabulate\n",
        "\n",
        "txt = \"what does the image describe?\"\n",
        "inputs = token_cap(txt)\n",
        "\n",
        "url = ejemplo[\"image_link\"]\n",
        "patch_img = token_imag(url)[0]\n",
        "\n",
        "capP = token_cap(ejemplo[\"caption+\"])\n",
        "capN = token_cap(ejemplo[\"caption-\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "d9KSFxcpKZXj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits_output_P = ofa_model.forward(input_ids=inputs,patch_images=patch_img, decoder_input_ids=capP)"
      ],
      "metadata": {
        "id": "Ty8kUqjIKp8s"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits_output_N = ofa_model.forward(input_ids=inputs,patch_images=patch_img, decoder_input_ids=capN)"
      ],
      "metadata": {
        "id": "kToFyEgEKquS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zISxYTRq3w_p"
      },
      "outputs": [],
      "source": [
        "print(\"Caption +\")\n",
        "pro_medP , mul_proP, suma_log1P, suma_log2P = pro_logs(logits_output_P, captionP)\n",
        "\n",
        "\n",
        "print(\"------------------------------------------------------------------------------\")\n",
        "print(\"Caption -\")\n",
        "pro_medN , mul_proN, suma_log1N, suma_log2N = pro_logs(logits_output_N, captionN)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pro_med = 0\n",
        "suma_log1 = 0\n",
        "suma_log2 = 0\n",
        "if pro_medP > pro_medN:\n",
        "  pro_med = 1\n",
        "if suma_log1P > suma_log1N:\n",
        "  suma_log1 = 1\n",
        "if suma_log2P > suma_log2N:\n",
        "  suma_log2 = 1\n",
        "\n",
        "print(f\"Prob media :      {pro_med}\")\n",
        "print(f\"Suma logit1:      {suma_log1}\")\n",
        "print(f\"Suma logit2:      {suma_log2}\")"
      ],
      "metadata": {
        "id": "4uqXTKzD1UIU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "M4kOoA0miDFB"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}